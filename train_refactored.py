# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è®­ç»ƒè„šæœ¬ - é‡æ„ç‰ˆ
æ”¯æŒ chsims/chsimsv2/meld æ•°æ®é›†
"""

import os
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from typing import Dict

from config_refactored import get_config
from data_loader_refactored import create_dataloaders_refactored
from smsa_refactored import MultimodalEmotionModel_Refactored
from utils import (
    setup_seed, setup_logger, dict_to_str,
    MetricsCalculator, EarlyStopping,
    save_checkpoint, count_parameters,
    save_config, AverageMeter
)

# å°è¯•å¯¼å…¥æ¨¡æ€åˆ†æå™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from modality_contribution_analyzer import ModalityContributionAnalyzer
    MODALITY_ANALYZER_AVAILABLE = True
except ImportError:
    MODALITY_ANALYZER_AVAILABLE = False


class Trainer:
    """ç»Ÿä¸€è®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.device = config.device
        
        # è®¾ç½®éšæœºç§å­
        setup_seed(config.seed)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logger(config.log_dir, 'train')
        self.logger.info(str(config))
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(config.save_dir, exist_ok=True)
        
        # è®¾ç½®æŒ‡æ ‡è®°å½•æ–‡ä»¶
        self.metrics_file = getattr(config, 'metrics_file', None)
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.setup_data()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.setup_model()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.setup_optimizer()
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self.setup_criterion()
        
        # åˆå§‹åŒ–æŒ‡æ ‡è®¡ç®—å™¨å’Œæ—©åœ
        self.metrics_calc = MetricsCalculator()
        self.early_stopping = EarlyStopping(
            patience=config.early_stop_patience,
            mode=config.metric_mode,
            verbose=True,
        )
        
        self.best_metric = float('inf') if config.metric_mode == 'min' else float('-inf')
        self.best_epoch = 0
        
        # ====== æ¨¡æ€è´¡çŒ®åº¦åˆ†æå™¨ ======
        enable_analysis = getattr(config, 'enable_modality_analysis', False)
        if MODALITY_ANALYZER_AVAILABLE and enable_analysis:
            self.modality_analyzer = ModalityContributionAnalyzer(modalities=['social', 'context'])
            self.analyze_modality_every = getattr(config, 'analyze_modality_every', 10)
            self.modality_analysis_enabled = True
            self.modality_analysis_epochs = getattr(config, 'modality_analysis_epochs', 3)
            self.logger.info(f"âœ“ æ¨¡æ€åˆ†æå™¨å·²å¯ç”¨ (æ¯{self.analyze_modality_every}ä¸ªbatchåˆ†æ)")
            self.logger.info(f"  âš ï¸  æ³¨æ„ï¼šå³æ—¶æ¶ˆèåˆ†æä¼šå½±å“è®­ç»ƒé€Ÿåº¦")
        else:
            self.modality_analyzer = None
            self.modality_analysis_enabled = False
            if not enable_analysis:
                self.logger.info("â„¹ï¸  æ¨¡æ€åˆ†æå·²ç¦ç”¨ï¼ˆå¯é€šè¿‡ --enable_modality_analysis å¯ç”¨ï¼‰")
            elif not MODALITY_ANALYZER_AVAILABLE:
                self.logger.info("âš ï¸  æ¨¡æ€åˆ†æå™¨æœªå®‰è£…ï¼ˆmodality_contribution_analyzer.pyï¼‰")
        # ==========================================
    
    def setup_data(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        self.logger.info("Loading data...")
        self.logger.info(f"Dataset: {self.config.dataset_name}")
        
        self.train_loader, self.valid_loader, self.test_loader = create_dataloaders_refactored(
            data_dir=self.config.data_dir,
            batch_size=self.config.batch_size,
            num_workers=self.config.num_workers,
            seq_length=self.config.seq_length,
            augment_train=self.config.augment_train,
            noise_scale=self.config.noise_scale,
            cache_size=self.config.cache_size,
        )
        
        self.logger.info(f"Train samples: {len(self.train_loader.dataset)}")
        self.logger.info(f"Valid samples: {len(self.valid_loader.dataset)}")
        self.logger.info(f"Test samples: {len(self.test_loader.dataset)}")
    
    def setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        self.logger.info("Initializing model...")
        
        self.model = MultimodalEmotionModel_Refactored(
            text_input_dim=self.config.text_input_dim,
            audio_input_dim=self.config.audio_input_dim,
            video_input_dim=self.config.video_input_dim,
            text_global_dim=self.config.text_global_dim,
            social_dim=self.config.social_dim,
            context_dim=self.config.context_dim,
            hidden_dim=self.config.hidden_dim,
            model_config=self.config.model_config,
            num_ism_layers=self.config.num_ism_layers,
            num_coupled_layers=self.config.num_coupled_layers,
            num_labels=self.config.num_labels,
            fusion_hidden_dim=self.config.fusion_hidden_dim,
            dropout_p=self.config.dropout_p,
        ).to(self.device)
        
        num_params = count_parameters(self.model)
        self.logger.info(f"Model parameters: {num_params:,}")
    
    def setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay,
        )
        
        if self.config.scheduler_type == 'step':
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.scheduler_step_size,
                gamma=self.config.scheduler_gamma,
            )
        elif self.config.scheduler_type == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.num_epochs,
            )
        elif self.config.scheduler_type == 'reduce_on_plateau':
            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer,
                mode=self.config.metric_mode,
                factor=self.config.scheduler_gamma,
                patience=self.config.scheduler_patience,
            )
        else:
            self.scheduler = None
    
    def setup_criterion(self):
        """è®¾ç½®æŸå¤±å‡½æ•°"""
        if self.config.task_type == 'regression':
            # å°è¯•ä½¿ç”¨æ”¹è¿›çš„æŸå¤±å‡½æ•°
            loss_type = getattr(self.config, 'loss_function', 'mse')
            
            if loss_type == 'l1' or loss_type == 'mae':
                self.criterion = nn.L1Loss()
                self.logger.info("âœ“ ä½¿ç”¨ L1 Loss (MAE)")
            elif loss_type == 'focal_mse':
                try:
                    from losses import FocalMSELoss
                    self.criterion = FocalMSELoss(gamma=2.0)
                    self.logger.info("âœ“ ä½¿ç”¨ Focal MSE Loss (gamma=2.0)")
                except ImportError:
                    self.logger.warning("âš ï¸  losses.pyä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†MSE Loss")
                    self.criterion = nn.MSELoss()
            elif loss_type == 'huber':
                try:
                    from losses import HuberLoss
                    self.criterion = HuberLoss(delta=1.0)
                    self.logger.info("âœ“ ä½¿ç”¨ Huber Loss (delta=1.0)")
                except ImportError:
                    self.logger.warning("âš ï¸  losses.pyä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†MSE Loss")
                    self.criterion = nn.MSELoss()
            else:
                self.criterion = nn.MSELoss()
                self.logger.info("ä½¿ç”¨æ ‡å‡† MSE Loss")
        else:
            self.criterion = nn.CrossEntropyLoss()
    
    def log_metrics_to_file(self, epoch: int, train_metrics: Dict[str, float], 
                           valid_metrics: Dict[str, float], test_metrics: Dict[str, float] = None):
        """è®°å½•æ¯ä¸ªepochçš„æŒ‡æ ‡åˆ°txtæ–‡ä»¶"""
        if self.metrics_file is None:
            return
        
        try:
            with open(self.metrics_file, 'a') as f:
                f.write(f"{'='*60}\n")
                f.write(f"Epoch {epoch}/{self.config.num_epochs}\n")
                f.write(f"{'='*60}\n\n")
                
                # è®°å½•è®­ç»ƒé›†æŒ‡æ ‡
                f.write("è®­ç»ƒé›† (Train):\n")
                for key, value in train_metrics.items():
                    if isinstance(value, float):
                        f.write(f"  {key}: {value:.4f}\n")
                    else:
                        f.write(f"  {key}: {value}\n")
                f.write("\n")
                
                # è®°å½•éªŒè¯é›†æŒ‡æ ‡
                f.write("éªŒè¯é›† (Valid):\n")
                for key, value in valid_metrics.items():
                    if isinstance(value, float):
                        f.write(f"  {key}: {value:.4f}\n")
                    else:
                        f.write(f"  {key}: {value}\n")
                f.write("\n")
                
                # è®°å½•æµ‹è¯•é›†æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if test_metrics is not None:
                    f.write("æµ‹è¯•é›† (Test):\n")
                    for key, value in test_metrics.items():
                        if isinstance(value, float):
                            f.write(f"  {key}: {value:.4f}\n")
                        else:
                            f.write(f"  {key}: {value}\n")
                    f.write("\n")
                
                f.write("\n")
        except Exception as e:
            self.logger.warning(f"æ— æ³•å†™å…¥æŒ‡æ ‡æ–‡ä»¶: {e}")
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        loss_meter = AverageMeter()
        sphere_loss_meter = AverageMeter()
        
        pbar = tqdm(self.train_loader,
                    desc=f'Epoch {epoch}/{self.config.num_epochs} [Train]',
                    position=0,
                    leave=True,
                    ncols=120,  # å›ºå®šå®½åº¦ï¼Œé¿å…æ˜¾ç¤ºé—®é¢˜
                    bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}')  # ä¼˜åŒ–æ ¼å¼
        
        all_preds = []
        all_labels = []
        
        # ====== æ§åˆ¶å…³é”®å¸§æ—¥å¿— ======
        if self.config.model_config.use_key_frame_selector:
            if hasattr(self.model, 'key_frame_selector') and self.model.key_frame_selector is not None:
                enable_kf_log = getattr(self.config, 'enable_keyframe_logging', False)
                kfs_log_freq = getattr(self.config, 'keyframe_log_every', 32)
                
                if epoch == 1:
                    # ç¬¬1ä¸ªepochæ˜¾ç¤ºé…ç½®ä¿¡æ¯
                    self.logger.info(f"\n{'='*70}")
                    self.logger.info(f"ğŸ“Š å…³é”®å¸§é€‰æ‹©å™¨é…ç½®:")
                    self.logger.info(f"  use_key_frame_selector: {self.config.model_config.use_key_frame_selector}")
                    self.logger.info(f"  enable_keyframe_logging: {enable_kf_log}")
                    self.logger.info(f"  n_segments: {self.model.key_frame_selector.n_segments}")
                    self.logger.info(f"  frame_ratio: {self.model.key_frame_selector.frame_ratio}%")
                    
                    if enable_kf_log:
                        self.model.key_frame_selector.enable_logging = True
                        self.model.key_frame_selector.log_every = kfs_log_freq
                        self.model.key_frame_selector.logger = self.logger  # ä¼ é€’logger
                        self.logger.info(f"  âœ“ å…³é”®å¸§ç»Ÿè®¡å·²å¯ç”¨ (æ¯{kfs_log_freq}ä¸ªutteranceæ‰“å°)")
                    else:
                        self.model.key_frame_selector.enable_logging = False
                        self.logger.info(f"  â„¹ï¸  å…³é”®å¸§ç»Ÿè®¡å·²ç¦ç”¨")
                        self.logger.info(f"     å¯ç”¨æ–¹æ³•: ä¿®æ”¹train_unified.shä¸­çš„ENABLE_KEYFRAME_LOGGING=true")
                    self.logger.info(f"{'='*70}\n")
                else:
                    # ç¬¬2ä¸ªepochå¼€å§‹ç¦ç”¨æ—¥å¿—
                    self.model.key_frame_selector.enable_logging = False
        else:
            if epoch == 1:
                self.logger.info("â„¹ï¸  å…³é”®å¸§é€‰æ‹©å™¨å·²ç¦ç”¨")
        # ==========================================
        
        for batch_idx, batch in enumerate(pbar):
            
            # ====== æ¨¡æ€è´¡çŒ®åº¦åˆ†æ ======
            if (self.modality_analysis_enabled and 
                self.modality_analyzer is not None and
                epoch <= self.modality_analysis_epochs and
                batch_idx % self.analyze_modality_every == 0 and
                batch_idx > 0):
                
                self.logger.info(f"\n{'='*70}")
                self.logger.info(f"Epoch {epoch} | Batch {batch_idx}/{len(self.train_loader)} - æ¨¡æ€è´¡çŒ®åº¦åˆ†æ")
                self.logger.info(f"{'='*70}")
                
                try:
                    analysis_batch = {
                        'text': batch['text'].to(self.device),
                        'audio': batch['audio'].to(self.device),
                        'vision': batch['vision'].to(self.device),
                        'text_global': batch['text_global'].to(self.device),
                        'social': batch['social'].to(self.device),
                        'context': batch['context'].to(self.device),
                        'label': batch['label'].to(self.device),
                    }
                    
                    scores = self.modality_analyzer.comprehensive_analysis(
                        self.model, analysis_batch, self.criterion, 
                        analyze_gradient=False, analyze_variance=False
                    )
                    report = self.modality_analyzer.format_analysis_results(scores)
                    self.logger.info(report)
                except Exception as e:
                    self.logger.warning(f"æ¨¡æ€åˆ†æå¤±è´¥: {e}")
            # ==========================================
            
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
            text_seq = batch['text'].to(self.device)
            audio_seq = batch['audio'].to(self.device)
            video_seq = batch['vision'].to(self.device)
            text_global = batch['text_global'].to(self.device)
            social = batch['social'].to(self.device)
            context = batch['context'].to(self.device)
            labels = batch['label'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            # â­ ä¿®å¤ï¼šä¸ºè¶…å›¾æä¾›æ­£ç¡®çš„batch_dia_lenï¼ˆæ¯ä¸ªæ ·æœ¬æ˜¯ç‹¬ç«‹å¯¹è¯ï¼‰
            batch_dia_len_for_hypergraph = [1] * text_seq.size(0) if self.config.model_config.use_hypergraph else None
            
            logits, aux_outputs = self.model(
                text_sequence=text_seq,
                audio_sequence=audio_seq,
                video_sequence=video_seq,
                text_global=text_global,
                social_embedding=social,
                context_embedding=context,
                batch_dia_len=batch_dia_len_for_hypergraph,  # â­ ä¿®å¤ï¼šä¼ å…¥æ­£ç¡®çš„å¯¹è¯é•¿åº¦
            )
            
            # è®¡ç®—æŸå¤±
            if self.config.task_type == 'regression':
                loss = self.criterion(logits.squeeze(-1), labels.squeeze(-1))
            else:
                loss = self.criterion(logits, labels.long().squeeze())
            
            # æ·»åŠ è¶…çƒé¢æ­£åˆ™åŒ–æŸå¤±
            sphere_loss = aux_outputs['sphere_loss']
            total_loss = loss + self.config.sphere_loss_weight * sphere_loss
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            if self.config.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip)
            
            self.optimizer.step()
            
            # æ›´æ–°ç»Ÿè®¡
            loss_meter.update(loss.item(), text_seq.size(0))
            sphere_loss_meter.update(sphere_loss.item(), text_seq.size(0))
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
            all_preds.append(logits.detach().cpu())
            all_labels.append(labels.detach().cpu())
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{loss_meter.avg:.4f}',
                'sph_loss': f'{sphere_loss_meter.avg:.4f}',
                'lr': f'{self.optimizer.param_groups[0]["lr"]:.2e}',
            })
        
        # è®¡ç®—æŒ‡æ ‡
        all_preds = torch.cat(all_preds, dim=0).numpy()
        all_labels = torch.cat(all_labels, dim=0).numpy()
        
        if self.config.task_type == 'regression':
            if self.config.metrics_type == 'chsims':
                # åœ¨ç¬¬ä¸€ä¸ªepochå¯ç”¨è°ƒè¯•è¾“å‡º
                debug_mode = (epoch == 1)
                metrics = self.metrics_calc.calc_chsims_metrics(all_preds.squeeze(), all_labels.squeeze(), debug=debug_mode)
            else:
                metrics = self.metrics_calc.calc_regression_metrics(all_preds.squeeze(), all_labels.squeeze())
        else:
            pred_classes = all_preds.argmax(axis=1)
            if self.config.metrics_type == 'meld':
                # MELDä¸“ç”¨æŒ‡æ ‡ï¼šåŒ…å«æ¯ä¸ªæƒ…æ„Ÿç±»åˆ«çš„ACC/F1
                metrics = self.metrics_calc.calc_meld_metrics(pred_classes, all_labels.squeeze().astype(int))
            else:
                metrics = self.metrics_calc.calc_classification_metrics(pred_classes, all_labels.squeeze(), self.config.num_labels)
        
        metrics['loss'] = loss_meter.avg
        metrics['sphere_loss'] = sphere_loss_meter.avg
        
        return metrics
    
    def evaluate(self, dataloader, split='valid') -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        
        loss_meter = AverageMeter()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            pbar = tqdm(dataloader, 
                       desc=f'{split.capitalize()} ', 
                       leave=False,
                       ncols=120,
                       bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}')
            
            for batch in pbar:
                text_seq = batch['text'].to(self.device)
                audio_seq = batch['audio'].to(self.device)
                video_seq = batch['vision'].to(self.device)
                text_global = batch['text_global'].to(self.device)
                social = batch['social'].to(self.device)
                context = batch['context'].to(self.device)
                labels = batch['label'].to(self.device)
                
                # â­ ä¿®å¤ï¼šä¸ºè¶…å›¾æä¾›æ­£ç¡®çš„batch_dia_len
                batch_dia_len_for_hypergraph = [1] * text_seq.size(0) if self.config.model_config.use_hypergraph else None
                
                logits, aux_outputs = self.model(
                    text_sequence=text_seq,
                    audio_sequence=audio_seq,
                    video_sequence=video_seq,
                    text_global=text_global,
                    social_embedding=social,
                    context_embedding=context,
                    batch_dia_len=batch_dia_len_for_hypergraph,  # â­ ä¿®å¤
                )
                
                if self.config.task_type == 'regression':
                    loss = self.criterion(logits.squeeze(-1), labels.squeeze(-1))
                else:
                    loss = self.criterion(logits, labels.long().squeeze())
                
                loss_meter.update(loss.item(), text_seq.size(0))
                
                all_preds.append(logits.detach().cpu())
                all_labels.append(labels.detach().cpu())
        
        # è®¡ç®—æŒ‡æ ‡
        all_preds = torch.cat(all_preds, dim=0).numpy()
        all_labels = torch.cat(all_labels, dim=0).numpy()
        
        if self.config.task_type == 'regression':
            if self.config.metrics_type == 'chsims':
                # åœ¨éªŒè¯é›†ç¬¬ä¸€æ¬¡è¯„ä¼°æ—¶å¯ç”¨è°ƒè¯•è¾“å‡º
                debug_mode = (split == 'valid' and not hasattr(self, '_debug_done'))
                if debug_mode:
                    self._debug_done = True
                metrics = self.metrics_calc.calc_chsims_metrics(all_preds.squeeze(), all_labels.squeeze(), debug=debug_mode)
            else:
                metrics = self.metrics_calc.calc_regression_metrics(all_preds.squeeze(), all_labels.squeeze())
        else:
            pred_classes = all_preds.argmax(axis=1)
            if self.config.metrics_type == 'meld':
                # MELDä¸“ç”¨æŒ‡æ ‡ï¼šåŒ…å«æ¯ä¸ªæƒ…æ„Ÿç±»åˆ«çš„ACC/F1
                metrics = self.metrics_calc.calc_meld_metrics(pred_classes, all_labels.squeeze().astype(int))
            else:
                metrics = self.metrics_calc.calc_classification_metrics(pred_classes, all_labels.squeeze(), self.config.num_labels)
        
        metrics['loss'] = loss_meter.avg
        
        return metrics
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        self.logger.info("Starting training...")
        
        for epoch in range(1, self.config.num_epochs + 1):
            # è®­ç»ƒ
            train_metrics = self.train_epoch(epoch)
            
            # éªŒè¯
            valid_metrics = self.evaluate(self.valid_loader, 'valid')
            
            # æ—¥å¿—
            self.logger.info(f"\nEpoch {epoch}/{self.config.num_epochs}")
            self.logger.info(f"Train: {dict_to_str(train_metrics)}")
            self.logger.info(f"Valid: {dict_to_str(valid_metrics)}")
            
            # æ¯ä¸ªepochåè¯„ä¼°æµ‹è¯•é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            test_metrics_epoch = None
            if getattr(self.config, 'eval_test_every_epoch', False):
                self.logger.info(f"\n{'='*60}")
                self.logger.info(f"Epoch {epoch} - æµ‹è¯•é›†è¯„ä¼°ï¼ˆä»…ç›‘æ§ï¼Œä¸å½±å“æ—©åœï¼‰")
                self.logger.info(f"{'='*60}")
                test_metrics_epoch = self.evaluate(self.test_loader, split='test')
                self.logger.info(f"Test: {dict_to_str(test_metrics_epoch)}")
                self.logger.info(f"{'='*60}\n")
            
            # è®°å½•æŒ‡æ ‡åˆ°txtæ–‡ä»¶
            self.log_metrics_to_file(epoch, train_metrics, valid_metrics, test_metrics_epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler is not None:
                if self.config.scheduler_type == 'reduce_on_plateau':
                    monitor_metric = valid_metrics.get('mae', valid_metrics.get('loss'))
                    self.scheduler.step(monitor_metric)
                else:
                    self.scheduler.step()
            
            # æ—©åœæ£€æŸ¥
            # ä½¿ç”¨é…ç½®æŒ‡å®šçš„æŒ‡æ ‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°é»˜è®¤
            metric_name = getattr(self.config, 'early_stop_metric', 'mae')
            
            # â­ æ–°å¢ï¼šæ”¯æŒç»¼åˆæŒ‡æ ‡
            if metric_name == 'composite':
                # è®¡ç®—ç»¼åˆåˆ†æ•°ï¼ˆå½’ä¸€åŒ–ååŠ æƒï¼‰
                mae_score = -valid_metrics.get('MAE', 1.0)  # è´Ÿå€¼ï¼Œå› ä¸ºè¶Šå°è¶Šå¥½
                corr_score = valid_metrics.get('Corr', 0.0)
                acc5_score = valid_metrics.get('Acc_5', 0.0)
                
                monitor_metric = (
                    self.config.composite_mae_weight * mae_score +
                    self.config.composite_corr_weight * corr_score +
                    self.config.composite_acc5_weight * acc5_score
                )
                
                self.logger.info(f"  Composite Score: {monitor_metric:.4f} "
                               f"(MAE={mae_score:.3f}, Corr={corr_score:.3f}, Acc5={acc5_score:.3f})")
            else:
                # å¤„ç†å¤§å°å†™ä¸åŒ¹é…ï¼šutils.pyè¿”å›çš„é”®æ˜¯Acc_2, F1_2ç­‰ï¼ˆé¦–å­—æ¯å¤§å†™ï¼‰
                metric_name_variants = [
                    metric_name,  # åŸå§‹ï¼šacc_2
                    metric_name.upper(),  # å…¨å¤§å†™ï¼šACC_2
                    'Acc_2' if metric_name == 'acc_2' else metric_name,
                    'Acc_3' if metric_name == 'acc_3' else metric_name,
                    'F1_2' if metric_name == 'f1_2' else metric_name,
                    'F1_3' if metric_name == 'f1_3' else metric_name,
                    'F1_5' if metric_name == 'f1_5' else metric_name,
                    'Acc_5' if metric_name == 'acc_5' else metric_name,
                    'MAE' if metric_name == 'mae' else metric_name,
                    'Corr' if metric_name == 'corr' else metric_name,
                ]
                monitor_metric = None
                for variant in metric_name_variants:
                    if variant in valid_metrics:
                        monitor_metric = valid_metrics[variant]
                        break
                if monitor_metric is None:
                    monitor_metric = valid_metrics.get('MAE', valid_metrics.get('loss', 0.0))
            
            if self.config.metric_mode == 'min':
                is_best = monitor_metric < self.best_metric
            else:
                is_best = monitor_metric > self.best_metric
            
            if is_best:
                self.best_metric = monitor_metric
                self.best_epoch = epoch
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                save_path = os.path.join(self.config.save_dir, 'best_model.pth')
                save_checkpoint(
                    model=self.model,
                    optimizer=self.optimizer,
                    scheduler=self.scheduler,
                    epoch=epoch,
                    metrics=valid_metrics,
                    save_path=save_path,
                    is_best=True,
                )
                
                self.logger.info(f"âœ“ Best model saved! (metric: {self.best_metric:.4f})")
            
            # æ—©åœ
            self.early_stopping(monitor_metric, epoch)
            if self.early_stopping.early_stop:
                self.logger.info(f"Early stopping triggered at epoch {epoch}")
                break
        
        # æµ‹è¯•
        self.logger.info("\nEvaluating on test set...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        checkpoint = torch.load(
            os.path.join(self.config.save_dir, 'best_model.pth'),
            map_location=self.device,
            weights_only=False  # PyTorch 2.6+ éœ€è¦æ­¤å‚æ•°
        )
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        test_metrics = self.evaluate(self.test_loader, 'test')
        self.logger.info(f"Test: {dict_to_str(test_metrics)}")
        
        self.logger.info(f"\nTraining completed! Best epoch: {self.best_epoch}")
        self.logger.info(f"Best validation metric: {self.best_metric:.4f}")


def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€è®­ç»ƒè„šæœ¬ - é‡æ„ç‰ˆ')
    parser.add_argument('--dataset', type=str, required=True,
                        choices=['chsims', 'chsimsv2', 'meld'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--batch_size', type=int, default=None,
                        help='æ‰¹å¤§å°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--learning_rate', type=float, default=None,
                        help='å­¦ä¹ ç‡ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--num_epochs', type=int, default=None,
                        help='è®­ç»ƒè½®æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--data_dir', type=str, default=None,
                        help='æ•°æ®é›†ç›®å½•è·¯å¾„ï¼ˆè¦†ç›–é»˜è®¤è·¯å¾„ï¼‰')
    parser.add_argument('--early_stop_patience', type=int, default=None,
                        help='æ—©åœç­‰å¾…è½®æ•°ï¼ˆå¯é€‰ï¼Œ0=ç¦ç”¨æ—©åœï¼‰')
    parser.add_argument('--early_stop_metric', type=str, default=None,
                        choices=['mae', 'loss', 'acc_2', 'acc_3', 'acc_5', 'f1_2', 'f1_3', 'f1_5', 'corr', 'composite'],
                        help='æ—©åœç›‘æ§æŒ‡æ ‡ï¼ˆcompositeä¸ºç»¼åˆæŒ‡æ ‡ï¼š0.4*MAE + 0.3*Corr + 0.3*Acc5ï¼‰')
    parser.add_argument('--sphere_loss_weight', type=float, default=None,
                        help='è¶…çƒä½“æŸå¤±æƒé‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤0.01ï¼‰')
    parser.add_argument('--hidden_dim', type=int, default=None,
                        help='éšè—å±‚ç»´åº¦ï¼ˆå¯é€‰ï¼Œé»˜è®¤256ï¼‰')
    parser.add_argument('--dropout_p', type=float, default=None,
                        help='Dropoutç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤0.1ï¼‰')
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨å‚æ•°
    parser.add_argument('--scheduler_type', type=str, default=None,
                        choices=['step', 'cosine', 'reduce_on_plateau', 'none'],
                        help='å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤cosineï¼‰')
    parser.add_argument('--scheduler_gamma', type=float, default=None,
                        help='å­¦ä¹ ç‡è¡°å‡ç³»æ•°ï¼ˆé»˜è®¤0.5ï¼‰')
    parser.add_argument('--scheduler_patience', type=int, default=None,
                        help='ç­‰å¾…è½®æ•°ï¼ˆé»˜è®¤5ï¼Œä»…ç”¨äºreduce_on_plateauï¼‰')
    parser.add_argument('--scheduler_step_size', type=int, default=None,
                        help='æ­¥é•¿ï¼ˆé»˜è®¤10ï¼Œä»…ç”¨äºstepï¼‰')
    
    # ç»„ä»¶å‚æ•°
    parser.add_argument('--n_key_frames', type=int, default=None,
                        help='å…³é”®å¸§æ•°é‡ï¼ˆå¯é€‰ï¼Œæ—§ç‰ˆå‚æ•°ï¼Œä¼˜å…ˆçº§ä½äºn_segments/frame_ratioï¼‰')
    parser.add_argument('--key_frame_segment_size', type=int, default=None,
                        help='å…³é”®å¸§åˆ†æ®µå¤§å°ï¼ˆå¯é€‰ï¼Œæ—§ç‰ˆå‚æ•°ï¼Œä¼˜å…ˆçº§ä½äºn_segments/frame_ratioï¼‰')
    # æ–°çš„ç™¾åˆ†æ¯”æ¨¡å¼å‚æ•°
    parser.add_argument('--n_segments', type=int, default=None,
                        help='MDP3åˆ†æ®µæ•°ï¼ˆé»˜è®¤ï¼šconfig.model_config.n_segmentsï¼‰')
    parser.add_argument('--frame_ratio', type=int, default=None,
                        help='æ¯æ®µé€‰æ‹©çš„å¸§ç™¾åˆ†æ¯”ï¼Œ1-100ï¼ˆé»˜è®¤ï¼šconfig.model_config.frame_ratioï¼‰')
    parser.add_argument('--num_film_experts', type=int, default=None,
                        help='MoE-FiLMä¸“å®¶æ•°é‡ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--film_top_k', type=int, default=None,
                        help='FiLM Top-Ké€‰æ‹©ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--num_hypergraph_layers', type=int, default=None,
                        help='è¶…å›¾å±‚æ•°ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--num_fourier_layers', type=int, default=None,
                        help='å‚…é‡Œå¶å±‚æ•°ï¼ˆå¯é€‰ï¼‰')
    
    # æ¨¡æ€å’Œå…³é”®å¸§åˆ†æå‚æ•° â­ æ–°å¢
    parser.add_argument('--enable_modality_analysis', action='store_true',
                        help='å¯ç”¨æ¨¡æ€è´¡çŒ®åº¦åˆ†æï¼ˆä¼šå½±å“è®­ç»ƒé€Ÿåº¦ï¼‰')
    parser.add_argument('--analyze_modality_every', type=int, default=None,
                        help='æ¯Nä¸ªbatchè¿›è¡Œæ¨¡æ€åˆ†æï¼ˆé»˜è®¤ï¼š10ï¼Œé€‚åº”å°æ•°æ®é›†ï¼‰')
    parser.add_argument('--keyframe_log_every', type=int, default=None,
                        help='æ¯Nä¸ªutteranceæ‰“å°å…³é”®å¸§ç»Ÿè®¡ï¼ˆé»˜è®¤ï¼š32ï¼‰')
    parser.add_argument('--modality_analysis_epochs', type=int, default=None,
                        help='åœ¨å‰Nä¸ªepochè¿›è¡Œæ¨¡æ€åˆ†æï¼ˆé»˜è®¤ï¼š3ï¼‰')
    parser.add_argument('--enable_keyframe_logging', action='store_true',
                        help='å¯ç”¨å…³é”®å¸§ç»Ÿè®¡æ‰“å°')
    parser.add_argument('--eval_test_every_epoch', action='store_true',
                        help='æ¯ä¸ªepochååœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆä»…ç›‘æ§ï¼Œä¸å½±å“æ—©åœï¼‰')
    
    # ç»„ä»¶å¼€å…³ï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰
    parser.add_argument('--no_key_frame_selector', action='store_true',
                        help='ç¦ç”¨å…³é”®å¸§é€‰æ‹©')
    parser.add_argument('--no_coupled_mamba', action='store_true',
                        help='ç¦ç”¨Coupled Mambaï¼ˆä½¿ç”¨ç‹¬ç«‹Mambaï¼‰')
    parser.add_argument('--no_moe_film', action='store_true',
                        help='ç¦ç”¨MoE-FiLMè°ƒåˆ¶')
    parser.add_argument('--no_hypergraph', action='store_true',
                        help='ç¦ç”¨è¶…å›¾å»ºæ¨¡')
    parser.add_argument('--no_frequency_decomp', action='store_true',
                        help='ç¦ç”¨é¢‘åŸŸåˆ†è§£')
    parser.add_argument('--no_sphere_reg', action='store_true',
                        help='ç¦ç”¨è¶…çƒä½“æ­£åˆ™åŒ–')
    parser.add_argument('--no_direct_fusion_priors', action='store_true',
                        help='ç¦æ­¢social/contextç›´æ¥å‚ä¸èåˆï¼ˆåªç”¨äºFiLMè°ƒåˆ¶ï¼‰')
    parser.add_argument('--use_improved_mlp', action='store_true',
                        help='ä½¿ç”¨æ”¹è¿›ç‰ˆMLPï¼ˆ4å±‚æ·±å±‚+GELU+æ®‹å·®+LayerNormï¼‰')
    
    # æŒ‡æ ‡è®°å½•æ–‡ä»¶
    parser.add_argument('--metrics_file', type=str, default=None,
                        help='æŒ‡æ ‡è®°å½•æ–‡ä»¶è·¯å¾„ï¼ˆtxtæ–‡ä»¶ï¼‰')
    
    # å¤šGPUæ”¯æŒï¼šè‡ªå®šä¹‰ä¿å­˜ç›®å½•
    parser.add_argument('--save_dir', type=str, default=None,
                        help='æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆç”¨äºå¤šGPUå¹¶è¡Œè®­ç»ƒé¿å…å†²çªï¼‰')
    parser.add_argument('--log_dir', type=str, default=None,
                        help='æ—¥å¿—ç›®å½•ï¼ˆç”¨äºå¤šGPUå¹¶è¡Œè®­ç»ƒé¿å…å†²çªï¼‰')
    
    args = parser.parse_args()
    
    # è·å–é…ç½®
    config = get_config(args.dataset)
    
    # è¦†ç›–åŸºç¡€å‚æ•°
    if args.data_dir is not None:
        config.data_dir = args.data_dir
    if args.batch_size is not None:
        config.batch_size = args.batch_size
    if args.learning_rate is not None:
        config.learning_rate = args.learning_rate
    if args.num_epochs is not None:
        config.num_epochs = args.num_epochs
    if args.early_stop_patience is not None:
        config.early_stop_patience = args.early_stop_patience
    if args.early_stop_metric is not None:
        config.early_stop_metric = args.early_stop_metric
    if args.sphere_loss_weight is not None:
        config.sphere_loss_weight = args.sphere_loss_weight
    if args.hidden_dim is not None:
        config.hidden_dim = args.hidden_dim
    if args.dropout_p is not None:
        config.dropout_p = args.dropout_p
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨å‚æ•°
    if args.scheduler_type is not None:
        config.scheduler_type = args.scheduler_type
    if args.scheduler_gamma is not None:
        config.scheduler_gamma = args.scheduler_gamma
    if args.scheduler_patience is not None:
        config.scheduler_patience = args.scheduler_patience
    if args.scheduler_step_size is not None:
        config.scheduler_step_size = args.scheduler_step_size
    
    # æ¨¡æ€å’Œå…³é”®å¸§åˆ†æå‚æ•°
    if args.enable_modality_analysis:
        config.enable_modality_analysis = True
    if args.analyze_modality_every is not None:
        config.analyze_modality_every = args.analyze_modality_every
    if args.keyframe_log_every is not None:
        config.keyframe_log_every = args.keyframe_log_every
    if args.modality_analysis_epochs is not None:
        config.modality_analysis_epochs = args.modality_analysis_epochs
    if args.enable_keyframe_logging:
        config.enable_keyframe_logging = True
    if args.eval_test_every_epoch:
        config.eval_test_every_epoch = True
    
    # åº”ç”¨ç»„ä»¶å‚æ•°
    if args.n_segments is not None:
        config.model_config.n_segments = max(1, args.n_segments)
    if args.frame_ratio is not None:
        if not (1 <= args.frame_ratio <= 100):
            raise ValueError("--frame_ratio å¿…é¡»åœ¨1åˆ°100ä¹‹é—´")
        config.model_config.frame_ratio = args.frame_ratio
    # å…¼å®¹æ—§å‚æ•°ï¼šè‹¥ç”¨æˆ·ä»ç„¶ä½¿ç”¨n_key_frames/key_frame_segment_sizeï¼Œåˆ™å›é€€åˆ°å›ºå®šå¸§æ•°æ¨¡å¼
    if args.n_key_frames is not None:
        config.model_config.n_key_frames = args.n_key_frames
    if args.key_frame_segment_size is not None:
        config.model_config.key_frame_segment_size = args.key_frame_segment_size
    if args.num_film_experts is not None:
        config.model_config.num_film_experts = args.num_film_experts
    if args.film_top_k is not None:
        config.model_config.film_top_k = args.film_top_k
    if args.num_hypergraph_layers is not None:
        config.model_config.num_hypergraph_layers = args.num_hypergraph_layers
    if args.num_fourier_layers is not None:
        config.model_config.num_fourier_layers = args.num_fourier_layers
    
    # åº”ç”¨ç»„ä»¶å¼€å…³
    if args.no_key_frame_selector:
        config.model_config.use_key_frame_selector = False
    if args.no_coupled_mamba:
        config.model_config.use_coupled_mamba = False
    if args.no_moe_film:
        config.model_config.use_moe_film = False
    if args.no_hypergraph:
        config.model_config.use_hypergraph = False
    if args.no_frequency_decomp:
        config.model_config.use_frequency_decomp = False
    if args.no_sphere_reg:
        config.model_config.use_sphere_regularization = False
    if args.no_direct_fusion_priors:
        config.model_config.direct_fusion_priors = False
    if args.use_improved_mlp:
        config.model_config.use_improved_mlp = True
    
    # æŒ‡æ ‡è®°å½•æ–‡ä»¶
    if args.metrics_file is not None:
        config.metrics_file = args.metrics_file
    
    # å¤šGPUæ”¯æŒï¼šè‡ªå®šä¹‰ä¿å­˜ç›®å½•å’Œæ—¥å¿—ç›®å½•
    if args.save_dir is not None:
        config.save_dir = args.save_dir
    if args.log_dir is not None:
        config.log_dir = args.log_dir
    
    # è®­ç»ƒ
    trainer = Trainer(config)
    trainer.train()


if __name__ == '__main__':
    main()

